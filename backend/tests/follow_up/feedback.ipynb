{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d00e055d",
   "metadata": {},
   "source": [
    "### Runpod 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "256290dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# 모델 저장 경로를 네트워크 볼륨(/workspace) 내부로 지정\n",
    "os.environ[\"HF_HOME\"] = \"/workspace/hf_cache\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b65e95d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 필수 라이브러리 설치/업데이트\n",
    "!pip install transformers accelerate bitsandbytes openai torch nltk huggingface_hub bert-score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2bf7804a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0bf3320d3dcb4d21ae84ac45350184a0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.sv…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from huggingface_hub import notebook_login\n",
    "notebook_login()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a501ba5",
   "metadata": {},
   "source": [
    "---\n",
    "### GPT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "97bc36e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import json\n",
    "import openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "0cd37760",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_feedback_openai(model_name, prompt):\n",
    "    start_time = time.perf_counter()\n",
    "    ttft = 0\n",
    "    generated_tokens = 0\n",
    "    content = \"\"\n",
    "    first_token_received = False\n",
    "    \n",
    "    try:\n",
    "        response = openai.chat.completions.create(\n",
    "            model=model_name,\n",
    "            messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "            temperature=0,\n",
    "            response_format={\"type\": \"json_object\"},\n",
    "            stream=True,                              # 토큰 단위로 수신\n",
    "            stream_options={\"include_usage\": True}    # 마지막 chunk에 토큰 정보 포함\n",
    "        )\n",
    "        \n",
    "        for chunk in response:\n",
    "            # 첫번째 토큰이 들어오는 시점 확인 (ttft)\n",
    "            if not first_token_received and chunk.choices and chunk.choices[0].delta.content:\n",
    "                ttft = time.perf_counter() - start_time\n",
    "                first_token_received = True\n",
    "            \n",
    "            # 내용 누적\n",
    "            if chunk.choices and chunk.choices[0].delta.content:\n",
    "                content += chunk.choices[0].delta.content\n",
    "            \n",
    "            # 토큰 사용량 확인\n",
    "            if chunk.usage is not None:\n",
    "                generated_tokens = chunk.usage.completion_tokens\n",
    "        \n",
    "        end_time = time.perf_counter()\n",
    "        total_duration = end_time - start_time\n",
    "        \n",
    "        # tps 계산 (생성된 토큰 수 / 전체 소요 시간)\n",
    "        tps = generated_tokens / total_duration if total_duration > 0 else 0\n",
    "\n",
    "        result_json = json.loads(content)\n",
    "        \n",
    "        metrics = {\n",
    "                \"ttft\": round(ttft, 3),\n",
    "                \"tps\": round(tps, 2),\n",
    "                \"total_tokens\": generated_tokens\n",
    "            }\n",
    "\n",
    "        return result_json, metrics\n",
    "    except Exception as e:\n",
    "        return f\"{model_name} 호출 중 오류 발생 : {e}\", \"오류\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b0999e4",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b837961",
   "metadata": {},
   "source": [
    "### sllm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e2335a07",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import json\n",
    "import time\n",
    "import torch\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer, TextIteratorStreamer\n",
    "from threading import Thread"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1c5f527f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_summary_sllm(model_name, prompt):\n",
    "    try:\n",
    "        # 모델 및 토크나이저 로드 (기존 유지)\n",
    "        tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "        model = AutoModelForCausalLM.from_pretrained(\n",
    "            model_name,\n",
    "            dtype=torch.bfloat16,\n",
    "            device_map=\"auto\",\n",
    "            trust_remote_code=True\n",
    "        )\n",
    "        \n",
    "        if tokenizer.pad_token is None:\n",
    "            tokenizer.pad_token = tokenizer.eos_token\n",
    "        \n",
    "        messages = [{\"role\": \"system\", \"content\": prompt}]\n",
    "        inputs = tokenizer.apply_chat_template(\n",
    "            messages, \n",
    "            tokenize=True, \n",
    "            add_generation_prompt=True, \n",
    "            return_tensors=\"pt\"\n",
    "        ).to(model.device)\n",
    "\n",
    "        streamer = TextIteratorStreamer(tokenizer, skip_prompt=True, skip_special_tokens=True)\n",
    "        \n",
    "        start_time = time.perf_counter()\n",
    "        ttft = 0\n",
    "        first_token_received = False\n",
    "        full_content = \"\"\n",
    "\n",
    "        generation_kwargs = dict(\n",
    "            input_ids=inputs,\n",
    "            streamer=streamer,\n",
    "            max_new_tokens=1024,  # [수정] 512는 너무 짧아 잘릴 수 있으므로 1024로 확장\n",
    "            repetition_penalty=1.2,\n",
    "            do_sample=False,\n",
    "            eos_token_id=tokenizer.eos_token_id,\n",
    "            pad_token_id=tokenizer.pad_token_id\n",
    "        )\n",
    "        \n",
    "        thread = Thread(target=model.generate, kwargs=generation_kwargs)\n",
    "        thread.start()\n",
    "\n",
    "        for new_text in streamer:\n",
    "            if not first_token_received and len(new_text) > 0:\n",
    "                ttft = time.perf_counter() - start_time\n",
    "                first_token_received = True\n",
    "            full_content += new_text\n",
    "\n",
    "        thread.join()\n",
    "        end_time = time.perf_counter()\n",
    "        \n",
    "        total_duration = end_time - start_time\n",
    "        generated_token_count = len(tokenizer.encode(full_content))\n",
    "        tps = generated_token_count / total_duration if total_duration > 0 else 0\n",
    "\n",
    "        # --- [JSON 추출 및 클리닝 파트 최적화] ---\n",
    "        content = {}\n",
    "        try:\n",
    "            # 1. 앞뒤 잡설 및 마크다운 태그 제거\n",
    "            cleaned_raw = re.sub(r'```json|```', '', full_content).strip()\n",
    "            cleaned_raw = re.sub(r'//.*', '', cleaned_raw) # 주석 제거\n",
    "            \n",
    "            # 2. 첫 번째 '{' 부터 마지막 '}' 까지만 추출\n",
    "            start_idx = cleaned_raw.find('{')\n",
    "            end_idx = cleaned_raw.rfind('}')\n",
    "            \n",
    "            if start_idx != -1:\n",
    "                # 만약 '}'가 없거나 형식이 깨졌을 경우를 대비해 잘린 부분 복구 시도\n",
    "                if end_idx == -1 or end_idx < start_idx:\n",
    "                    cleaned_raw = cleaned_raw[start_idx:] + '\"}}' # 최소한의 닫는 괄호 강제 추가\n",
    "                else:\n",
    "                    cleaned_raw = cleaned_raw[start_idx:end_idx+1]\n",
    "                \n",
    "                # 3. JSON 파싱\n",
    "                content = json.loads(cleaned_raw)\n",
    "            else:\n",
    "                content = {\"error\": \"JSON 형식을 찾을 수 없음\", \"raw\": full_content}\n",
    "        except json.JSONDecodeError:\n",
    "            # 파싱 실패 시, 따옴표가 안 닫힌 경우 등을 고려해 한 번 더 클리닝 시도\n",
    "            try:\n",
    "                # 따옴표나 괄호가 중간에 잘린 경우를 위한 강제 보정\n",
    "                fixed_raw = cleaned_raw.strip()\n",
    "                if not fixed_raw.endswith('}'): fixed_raw += '\"}'\n",
    "                if not fixed_raw.endswith('}'): fixed_raw += '}'\n",
    "                content = json.loads(fixed_raw)\n",
    "            except:\n",
    "                content = {\"error\": \"JSON 파싱 실패\", \"raw\": full_content}\n",
    "        # ------------------------------------------\n",
    "\n",
    "        del model, tokenizer, inputs\n",
    "        if torch.cuda.is_available():\n",
    "            torch.cuda.empty_cache()\n",
    "\n",
    "        metrics = {\n",
    "            \"ttft\": round(ttft, 3),\n",
    "            \"tps\": round(tps, 2),\n",
    "            \"total_tokens\": generated_token_count\n",
    "        }\n",
    "\n",
    "        return content, metrics\n",
    "\n",
    "    except Exception as e:\n",
    "        return f\"{model_name} 호출 중 오류 발생 : {e}\", None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da5fa9fe",
   "metadata": {},
   "source": [
    "### 테스트 코드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0322b33",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import glob\n",
    "\n",
    "# 파일 경로 설정\n",
    "testset_dir = \"./testsets\"\n",
    "json_files = glob.glob(os.path.join(testset_dir, \"*.json\"))\n",
    "\n",
    "results_list = []\n",
    "\n",
    "# 파일 루프 시작\n",
    "for file_path in json_files:\n",
    "    with open(file_path, 'r', encoding='utf-8') as f:\n",
    "        data_list = json.load(f)\n",
    "        \n",
    "    for item in data_list:\n",
    "        # 데이터 추출\n",
    "        script = item.get('consulting_content', \"\")\n",
    "        summary_ref = item['instructions'][0]['data'][0]['output']\n",
    "\n",
    "        print(f\"테스트 실행 중: {item.get('source_id', 'Unknown ID')}\")\n",
    "\n",
    "        # 모델 테스트\n",
    "        # prompt 생성\n",
    "        system_prompt = f\"\"\"\n",
    "        상담 스크립트를 평가 기준에 따라 객관적으로 평가하세요\n",
    "        \n",
    "        ### 제약 사항\n",
    "        1. 모든 감점에는 구체적인 발화 근거를 반드시 제시한다\n",
    "        2. 고객의 감사 표현은 고객 발화에서만 카운트한다\n",
    "        3. 추측, 설명 문장, 자연어 해설 금지 - JSON만 출력한다\n",
    "        4. 총 점수는 60점이며 각 2개 점수의 총합이다\n",
    "        \n",
    "        ### 상담 스크립트\n",
    "        {script}\n",
    "        \n",
    "        ### 평가 기준\n",
    "        1. 매뉴얼 준수 (50점에서 감점하는 방식)\n",
    "        intro\n",
    "        - 인사말\n",
    "          0점: 첫인사 + 마무리 멘트 모두 수행\n",
    "          -5점: 첫인사 또는 마무리 멘트 누락\n",
    "        - 고객확인\n",
    "          0점: 고객정보를 고객에게 직접 질문\n",
    "          -5점: 상담원이 고객정보를 먼저 발화하여 정보 누출\n",
    "        \n",
    "        response\n",
    "        - 호응어\n",
    "          0점: 공감/감성 호응\n",
    "          -5점: 기운 없음, 짜증 섞인 표현\n",
    "        - 대기 표현\n",
    "          0점: 대기 표현 모두 수행\n",
    "          -5점: 대기 표현 누락\n",
    "        \n",
    "        explanation\n",
    "        - 커뮤니케이션\n",
    "          0점: 핵심 요약 + 이해 쉬운 설명\n",
    "          -5점: 일방적 설명, 단답형\n",
    "        - 알기 쉬운 설명\n",
    "          0점: 고객 눈높이 설명 + 부연\n",
    "          -5점: 복잡한 설명/상담자 관점 설명\n",
    "        \n",
    "        proactivity\n",
    "        - 적극성\n",
    "           0점: 적극적 대응\n",
    "          -5점: 수동적 대응, 대안 없음\n",
    "        - 언어표현\n",
    "          0점: 정중/경어체/긍정 표현\n",
    "          -5점: 전문용어, 줄임말, 명령조, 무시 표현\n",
    "        \n",
    "        accuracy\n",
    "        - 정확한 업무처리\n",
    "          0점: 오류 없음\n",
    "          -10점: 임의 판단으로 업무 오류 발생\n",
    "        \n",
    "        2. 고객 감사 표현 (10점)\n",
    "        - 고객 발화 중 감사/칭찬 키워드 포함 시 1회 카운트\n",
    "        - 0회: 0점 / 1회: 5점 / 2회 이상: 10점\n",
    "        \n",
    "        \n",
    "        ### 출력 형식 (JSON)\n",
    "        {{\n",
    "          \"manual_compliance\": {{\n",
    "            \"intro\": {{\n",
    "              \"score\": 0,\n",
    "              \"evidence\": []\n",
    "            }},\n",
    "            \"response\": {{\n",
    "              \"score\": 0,\n",
    "              \"evidence\": []\n",
    "            }},\n",
    "            \"explanation\": {{\n",
    "              \"score\": 0,\n",
    "              \"evidence\": []\n",
    "            }},\n",
    "            \"proactivity\": {{\n",
    "              \"score\": 0,\n",
    "              \"evidence\": []\n",
    "            }},\n",
    "            \"accuracy\": {{\n",
    "              \"score\": 0,\n",
    "              \"evidence\": []\n",
    "            }},\n",
    "            \"manual_score\": \"0~50점\"\n",
    "          }},\n",
    "          \"customer_thanks\": {{\n",
    "            \"count\": 0,\n",
    "            \"thanks_score\": \"0~10점\",\n",
    "            \"evidence\": []\n",
    "          }},\n",
    "          \"final_score\": {{\n",
    "            \"total\": \"manual_score + thanks_score\",\n",
    "            \"feedback\": \"\"\n",
    "          }}\n",
    "        }}\n",
    "        \"\"\"\n",
    "        \n",
    "        res, metrics = generate_summary_sllm(\"kakaocorp/kanana-nano-2.1b-instruct\", system_prompt)\n",
    "        # res, metrics = generate_summary_sllm(\"kakaocorp/kanana-1.5-8b-instruct-2505\", system_prompt)\n",
    "        # res, metrics = generate_feedback_openai(\"gpt-4.1-mini\", system_prompt)\n",
    "            \n",
    "        # 결과 저장\n",
    "        results_list.append({\n",
    "            \"id\": item.get('source_id'),\n",
    "            \"res\": res,\n",
    "            \"metrics\": metrics,\n",
    "        })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "7586637b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "데이터가 추가되었습니다: evaluation_results_feedback.csv\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "df_new = pd.json_normalize(results_list)\n",
    "df_new['model'] = \"kanana-1.5-8b\" \n",
    "\n",
    "output_file = \"evaluation_results_feedback.csv\"\n",
    "\n",
    "if not os.path.exists(output_file):\n",
    "    df_new.to_csv(output_file, index=False, mode='w', encoding='utf-8-sig')\n",
    "else:\n",
    "    df_new.to_csv(output_file, index=False, mode='a', encoding='utf-8-sig', header=False)\n",
    "\n",
    "print(f\"데이터가 추가되었습니다: {output_file}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c70e997",
   "metadata": {},
   "source": [
    "---\n",
    "### 후처리 시간 및 감정 전환 평가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82f4e9bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "worktime = 100\n",
    "emotion_set = ['부정', '긍정', '부정']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "c29cd647",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_call(work_time, emotions):\n",
    "    work_score = 0\n",
    "    emotion_score = 0\n",
    "    \n",
    "    # 후처리 시간 평가\n",
    "    time_indicator = 90\n",
    "    \n",
    "    if work_time <= time_indicator:\n",
    "        work_score = 20\n",
    "    elif work_time >= 90:\n",
    "        if work_time < 120:\n",
    "            work_score = 15\n",
    "        elif work_time < 150:\n",
    "            work_score = 10\n",
    "        elif work_time < 200:\n",
    "            work_score = 5\n",
    "        else:\n",
    "            work_score = 0\n",
    "    \n",
    "    # 감정 전환 평가\n",
    "    def get_step_score(before, after):\n",
    "        if before == after:\n",
    "            return 3\n",
    "        \n",
    "        scores = {\n",
    "            (\"부정\", \"중립\"): 5,\n",
    "            (\"부정\", \"긍정\"): 10,\n",
    "            (\"중립\", \"긍정\"): 10,\n",
    "            (\"중립\", \"부정\"): 0,\n",
    "            (\"긍정\", \"부정\"): 0,\n",
    "            (\"긍정\", \"중립\"): 5\n",
    "        }\n",
    "        return scores.get((before, after), 0)\n",
    "\n",
    "    # 단계별 점수 계산\n",
    "    score_step_1 = get_step_score(emotions[0], emotions[1]) # 초반 -> 중반\n",
    "    score_step_2 = get_step_score(emotions[1], emotions[2]) # 중반 -> 후반\n",
    "    \n",
    "    emotion_score = score_step_1 + score_step_2\n",
    "    \n",
    "    return {\n",
    "        \"work_score\": work_score, \n",
    "        \"emotion_score\": emotion_score\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "e58335b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'work_score': 15, 'emotion_score': 10}"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score = evaluate_call(worktime, emotion_set)\n",
    "score"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
